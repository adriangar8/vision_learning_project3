{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f28f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import needed libraries\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from transformers import ResNetModel\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision.transforms import v2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b723e46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "base_path = 'C:/Users/Alex/Desktop/Universidad/Third Course/First Semester/Vision & Learning/PROJECT 3//'\n",
    "img_path = f'{base_path}Images/'\n",
    "cap_path = f'{base_path}captions.txt'\n",
    "\n",
    "data = pd.read_csv(cap_path)\n",
    "partitions = np.load('flickr8k_partitions.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b09b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ['<SOS>', '<EOS>', '<PAD>', ' ', '!', '\"', '#', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "NUM_CHAR = len(chars)\n",
    "idx2char = {k: v for k, v in enumerate(chars)}\n",
    "char2idx = {v: k for k, v in enumerate(chars)}\n",
    "\n",
    "TEXT_MAX_LEN = 201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ff6590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, data, partition):\n",
    "        self.data = data\n",
    "        self.partition = partition\n",
    "        self.num_captions = 5\n",
    "        self.max_len = TEXT_MAX_LEN\n",
    "        self.img_proc = torch.nn.Sequential(\n",
    "            v2.ToImage(),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Resize((224, 224), antialias=True),\n",
    "            v2.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.partition)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.num_captions*self.partition[idx]\n",
    "        item = self.data.iloc[real_idx: real_idx+self.num_captions]\n",
    "        ## image processing\n",
    "        img_name = item.image.reset_index(drop=True)[0]\n",
    "        img = Image.open(f'{img_path}{img_name}').convert('RGB')\n",
    "        img = self.img_proc(img)\n",
    "    \n",
    "        ## caption processing\n",
    "        caption = item.caption.reset_index(drop=True)[random.choice(list(range(self.num_captions)))]\n",
    "        cap_list = list(caption)\n",
    "        final_list = [chars[0]]\n",
    "        final_list.extend(cap_list)\n",
    "        final_list.extend([chars[1]])\n",
    "        gap = self.max_len - len(final_list)\n",
    "        final_list.extend([chars[2]]*gap)\n",
    "        cap_idx = torch.Tensor([char2idx[i] for i in final_list])\n",
    "        return img, cap_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b652abd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = ResNetModel.from_pretrained('microsoft/resnet-18').to(DEVICE)\n",
    "        self.gru = nn.GRU(512, 512, num_layers=1)\n",
    "        self.proj = nn.Linear(512, NUM_CHAR)\n",
    "        self.embed = nn.Embedding(NUM_CHAR, 512)\n",
    "\n",
    "    def forward(self, img):\n",
    "        batch_size = img.shape[0]\n",
    "        feat = self.resnet(img)\n",
    "        feat = feat.pooler_output.squeeze(-1).squeeze(-1).unsqueeze(0) # 1, batch, 512\n",
    "        start = torch.tensor(char2idx['<SOS>']).to(DEVICE)\n",
    "        start_embed = self.embed(start) # 512\n",
    "        start_embeds = start_embed.repeat(batch_size, 1).unsqueeze(0) # 1, batch, 512\n",
    "        inp = start_embeds\n",
    "        hidden = feat\n",
    "        for t in range(TEXT_MAX_LEN-1): # rm <SOS>\n",
    "            out, hidden = self.gru(inp, hidden)\n",
    "            inp = torch.cat((inp, out[-1:]), dim=0) # N, batch, 512\n",
    "    \n",
    "        res = inp.permute(1, 0, 2) # batch, seq, 512\n",
    "        res = self.proj(res) # batch, seq, 80\n",
    "        res = res.permute(0, 2, 1) # batch, 80, seq\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82acf476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_19292\\1240665556.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  caption1 = torch.tensor(caption1)\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_19292\\1240665556.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  caption2 = torch.tensor(caption2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3812, grad_fn=<NllLoss2DBackward0>)\n"
     ]
    }
   ],
   "source": [
    "'''A simple example to calculate loss of a single batch (size 2)'''\n",
    "dataset = Data(data, partitions['train'])\n",
    "img1, caption1 = next(iter(dataset))\n",
    "img2, caption2 = next(iter(dataset))\n",
    "caption1 = torch.tensor(caption1)\n",
    "caption2 = torch.tensor(caption2)\n",
    "img = torch.cat((img1.unsqueeze(0), img2.unsqueeze(0)))\n",
    "caption = torch.cat((caption1.unsqueeze(0), caption2.unsqueeze(0)))\n",
    "img, caption = img.to(DEVICE), caption.to(DEVICE)\n",
    "model = Model().to(DEVICE)\n",
    "pred = model(img)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "caption = caption.long()\n",
    "loss = crit(pred, caption)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3606f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Alex\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Alex\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Alex\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'bleu': 0.5946035575013605,\n",
       "  'precisions': [0.875, 0.7142857142857143, 0.5, 0.4],\n",
       "  'brevity_penalty': 1.0,\n",
       "  'length_ratio': 1.0,\n",
       "  'translation_length': 8,\n",
       "  'reference_length': 8},\n",
       " {'rouge1': 0.8571428571428571,\n",
       "  'rouge2': 0.6666666666666666,\n",
       "  'rougeL': 0.8571428571428571,\n",
       "  'rougeLsum': 0.8571428571428571},\n",
       " {'meteor': 0.864795918367347})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''metrics'''\n",
    "bleu = evaluate.load('bleu')\n",
    "meteor = evaluate.load('meteor')\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "reference = [['A child in a pink dress is climbing up a set of stairs in an entry way .', 'A girl going into a wooden building .']]\n",
    "prediction = ['A girl goes into a wooden building .']\n",
    "\n",
    "res_b = bleu.compute(predictions=prediction, references=reference)\n",
    "res_r = rouge.compute(predictions=prediction, references=reference)\n",
    "res_m = meteor.compute(predictions=prediction, references=reference)\n",
    "\n",
    "res_b, res_r, res_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7595f1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'bleu': 0.4723665527410147,\n",
       "  'precisions': [1.0, 1.0, 1.0, 1.0],\n",
       "  'brevity_penalty': 0.4723665527410147,\n",
       "  'length_ratio': 0.5714285714285714,\n",
       "  'translation_length': 4,\n",
       "  'reference_length': 7},\n",
       " {'rouge1': 0.7272727272727273,\n",
       "  'rouge2': 0.6666666666666666,\n",
       "  'rougeL': 0.7272727272727273,\n",
       "  'rougeLsum': 0.7272727272727273},\n",
       " {'meteor': 0.5923507462686567})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = [['A child is running in the campus']]\n",
    "pred1 = ['A child is running']\n",
    "\n",
    "res_b = bleu.compute(predictions=pred1, references=ref)\n",
    "res_r = rouge.compute(predictions=pred1, references=ref)\n",
    "res_m = meteor.compute(predictions=pred1, references=ref)\n",
    "\n",
    "res_b, res_r, res_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe24da77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'bleu': 0.0,\n",
       "  'precisions': [1.0, 1.0, 1.0, 0.0],\n",
       "  'brevity_penalty': 0.2635971381157267,\n",
       "  'length_ratio': 0.42857142857142855,\n",
       "  'translation_length': 3,\n",
       "  'reference_length': 7},\n",
       " {'rouge1': 0.6, 'rouge2': 0.5, 'rougeL': 0.6, 'rougeLsum': 0.6},\n",
       " {'meteor': 0.44612794612794615})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = [['A child is running in the campus']]\n",
    "pred1 = ['A child is']\n",
    "\n",
    "res_b = bleu.compute(predictions=pred1, references=ref)\n",
    "res_r = rouge.compute(predictions=pred1, references=ref)\n",
    "res_m = meteor.compute(predictions=pred1, references=ref)\n",
    "\n",
    "res_b, res_r, res_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca1afd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'bleu': 0.0,\n",
       "  'precisions': [1.0, 0.5, 0.0, 0.0],\n",
       "  'brevity_penalty': 0.2635971381157267,\n",
       "  'length_ratio': 0.42857142857142855,\n",
       "  'translation_length': 3,\n",
       "  'reference_length': 7},\n",
       " {'rouge1': 0.6, 'rouge2': 0.25, 'rougeL': 0.6, 'rougeLsum': 0.6},\n",
       " {'meteor': 0.3872053872053872},\n",
       " {'meteor': 0.45454545454545453})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = [['A child is running in the campus']]\n",
    "pred1 = ['A child campus']\n",
    "\n",
    "res_b = bleu.compute(predictions=pred1, references=ref)\n",
    "res_r = rouge.compute(predictions=pred1, references=ref)\n",
    "res_m = meteor.compute(predictions=pred1, references=ref)\n",
    "res_m_sin = meteor.compute(predictions=pred1, references=ref, gamma=0) # no penalty by setting gamma to 0\n",
    "\n",
    "res_b, res_r, res_m, res_m_sin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980bac05",
   "metadata": {},
   "source": [
    "Final metric we use for challenge 3: BLEU1, BLEU2, ROUGE-L, METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5433823c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BLEU-1:26.4%, BLEU2:18.6%, ROUGE-L:60.0%, METEOR:38.7%'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = [['A child is running in the campus']]\n",
    "pred1 = ['A child campus']\n",
    "\n",
    "bleu1 = bleu.compute(predictions=pred1, references=ref, max_order=1)\n",
    "bleu2 = bleu.compute(predictions=pred1, references=ref, max_order=2)\n",
    "res_r = rouge.compute(predictions=pred1, references=ref)\n",
    "res_m = meteor.compute(predictions=pred1, references=ref)\n",
    "\n",
    "f\"BLEU-1:{bleu1['bleu']*100:.1f}%, BLEU2:{bleu2['bleu']*100:.1f}%, ROUGE-L:{res_r['rougeL']*100:.1f}%, METEOR:{res_m['meteor']*100:.1f}%\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf5d9d",
   "metadata": {},
   "source": [
    "Now it is your turn! Try to finish the code below to run the train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = Data(data, partitions['train'])\n",
    "dataloader_train = DataLoader(data_train, batch_size=4, shuffle=True)\n",
    "batch= next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9835fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(EPOCHS):\n",
    "    data_train = Data(data, partitions['train'])\n",
    "    data_valid = Data(data, partitions['valid'])\n",
    "    data_test = Data(data, partitions['test'])\n",
    "\n",
    "    dataloader_train = DataLoader(data_train, batch_size=32, shuffle=True)\n",
    "    dataloader_valid = DataLoader(data_valid, batch_size=32, shuffle=True)\n",
    "    dataloader_test = DataLoader(data_test, batch_size=32, shuffle=True)\n",
    "    \n",
    "    model = Model().to(DEVICE)\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    metric = \"bleu1\"\n",
    "    #metric = \"bleu2\"\n",
    "    #metric = \"rouge\"\n",
    "    #metric = \"meteor\"\n",
    "    for epoch in range(EPOCHS):\n",
    "        loss, res = train_one_epoch(model, optimizer, crit, metric, dataloader_train)\n",
    "        print(f'train loss: {loss:.2f}, metric: {res:.2f}, epoch: {epoch}')\n",
    "        loss_v, res_v = eval_epoch(model, crit, metric, dataloader_valid)\n",
    "        print(f'valid loss: {loss:.2f}, metric: {res:.2f}')\n",
    "    loss_t, res_t = eval_epoch(model, crit, metric, dataloader_test)\n",
    "    print(f'test loss: {loss:.2f}, metric: {res:.2f}')\n",
    "    \n",
    "def train_one_epoch(model, optimizer, crit, metric, dataloader):\n",
    "    total_loss= 0.0\n",
    "    total_metric= 0.0\n",
    "    for batch in dataloader:\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.to(DEVICE) \n",
    "        \n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        \n",
    "        outputs= model(inputs)\n",
    "        targets = targets.long()\n",
    "        loss= crit(outputs,targets)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        METRIC = evaluate.load(str(metric).lower())\n",
    "\n",
    "        metriccompute = METRIC.compute(predictions=pred1, references=ref,max_order=1 )\n",
    "\n",
    "        if metric == \"rouge\":\n",
    "            total_metric += metriccompute['rougeL']\n",
    "        else:\n",
    "            total_metric += metriccompute[str(metric).lower()]\n",
    "        \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_metric = total_metric / len(dataloader)\n",
    "    print(f'train loss: {avg_loss:.2f}, metric: {avg_metric:.2f}')\n",
    "    \n",
    "    return avg_loss, avg_metric\n",
    "\n",
    "def eval_epoch(model, crit, metric, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_metric = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(DEVICE) \n",
    "            targets = targets.to(DEVICE)\n",
    "\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            targets = targets.long()\n",
    "            loss = crit(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            METRIC = evaluate.load(str(metric).lower())\n",
    "\n",
    "            metriccompute = METRIC.compute(predictions=pred1, references=ref,max_order=1 )\n",
    "\n",
    "            if metric == \"rouge\":\n",
    "                total_metric += metriccompute['rougeL']\n",
    "            else:\n",
    "                total_metric += metriccompute[str(metric).lower()]\n",
    "\n",
    "        \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_metric = (total_metric / len(dataloader)) * 100\n",
    "    print(f'valid loss: {avg_loss:.2f}, metric: {avg_metric:.2f}')\n",
    "    \n",
    "    return avg_loss, avg_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alex\\Desktop\\Universidad\\Third Course\\First Semester\\Vision & Learning\\PROJECT 3\\vl3\\vision_learning_project3\\Baseline Model and Metrics.ipynb Cell 18\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train(\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\Alex\\Desktop\\Universidad\\Third Course\\First Semester\\Vision & Learning\\PROJECT 3\\vl3\\vision_learning_project3\\Baseline Model and Metrics.ipynb Cell 18\u001b[0m line \u001b[0;36mtrain\u001b[1;34m(EPOCHS)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m#metric = \"bleu2\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X23sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#metric = \"rouge\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X23sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m#metric = \"meteor\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X23sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X23sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     loss, res \u001b[39m=\u001b[39m train_one_epoch(model, optimizer, crit, metric, dataloader_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X23sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, metric: \u001b[39m\u001b[39m{\u001b[39;00mres\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, epoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X23sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     loss_v, res_v \u001b[39m=\u001b[39m eval_epoch(model, crit, metric, dataloader_valid)\n",
      "\u001b[1;32mc:\\Users\\Alex\\Desktop\\Universidad\\Third Course\\First Semester\\Vision & Learning\\PROJECT 3\\vl3\\vision_learning_project3\\Baseline Model and Metrics.ipynb Cell 18\u001b[0m line \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, optimizer, crit, metric, dataloader)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X23sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(DEVICE) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X23sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X23sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m outputs\u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X23sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mlong()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X23sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m loss\u001b[39m=\u001b[39m crit(outputs,targets)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\Alex\\Desktop\\Universidad\\Third Course\\First Semester\\Vision & Learning\\PROJECT 3\\vl3\\vision_learning_project3\\Baseline Model and Metrics.ipynb Cell 18\u001b[0m line \u001b[0;36mModel.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X23sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m hidden \u001b[39m=\u001b[39m feat\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X23sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(TEXT_MAX_LEN\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m): \u001b[39m# rm <SOS>\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X23sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     out, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgru(inp, hidden)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X23sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     inp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((inp, out[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:]), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m# N, batch, 512\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X23sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m res \u001b[39m=\u001b[39m inp\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m) \u001b[39m# batch, seq, 512\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1102\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m   1101\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1102\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mgru(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m   1103\u001b[0m                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m   1104\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m   1106\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
