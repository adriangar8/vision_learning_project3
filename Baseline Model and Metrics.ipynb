{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f28f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import needed libraries\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from transformers import ResNetModel\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision.transforms import v2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b723e46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "base_path = 'C:/Users/Alex/Desktop/Universidad/Third Course/First Semester/Vision & Learning/PROJECT 3//'\n",
    "img_path = f'{base_path}Images/'\n",
    "cap_path = f'{base_path}captions.txt'\n",
    "\n",
    "data = pd.read_csv(cap_path)\n",
    "partitions = np.load('flickr8k_partitions.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b09b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ['<SOS>', '<EOS>', '<PAD>', ' ', '!', '\"', '#', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "NUM_CHAR = len(chars)\n",
    "idx2char = {k: v for k, v in enumerate(chars)}\n",
    "char2idx = {v: k for k, v in enumerate(chars)}\n",
    "\n",
    "TEXT_MAX_LEN = 201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<SOS>',\n",
       " 1: '<EOS>',\n",
       " 2: '<PAD>',\n",
       " 3: ' ',\n",
       " 4: '!',\n",
       " 5: '\"',\n",
       " 6: '#',\n",
       " 7: '&',\n",
       " 8: \"'\",\n",
       " 9: '(',\n",
       " 10: ')',\n",
       " 11: ',',\n",
       " 12: '-',\n",
       " 13: '.',\n",
       " 14: '0',\n",
       " 15: '1',\n",
       " 16: '2',\n",
       " 17: '3',\n",
       " 18: '4',\n",
       " 19: '5',\n",
       " 20: '6',\n",
       " 21: '7',\n",
       " 22: '8',\n",
       " 23: '9',\n",
       " 24: ':',\n",
       " 25: ';',\n",
       " 26: '=',\n",
       " 27: '?',\n",
       " 28: 'A',\n",
       " 29: 'B',\n",
       " 30: 'C',\n",
       " 31: 'D',\n",
       " 32: 'E',\n",
       " 33: 'F',\n",
       " 34: 'G',\n",
       " 35: 'H',\n",
       " 36: 'I',\n",
       " 37: 'J',\n",
       " 38: 'K',\n",
       " 39: 'L',\n",
       " 40: 'M',\n",
       " 41: 'N',\n",
       " 42: 'O',\n",
       " 43: 'P',\n",
       " 44: 'Q',\n",
       " 45: 'R',\n",
       " 46: 'S',\n",
       " 47: 'T',\n",
       " 48: 'U',\n",
       " 49: 'V',\n",
       " 50: 'W',\n",
       " 51: 'X',\n",
       " 52: 'Y',\n",
       " 53: 'Z',\n",
       " 54: 'a',\n",
       " 55: 'b',\n",
       " 56: 'c',\n",
       " 57: 'd',\n",
       " 58: 'e',\n",
       " 59: 'f',\n",
       " 60: 'g',\n",
       " 61: 'h',\n",
       " 62: 'i',\n",
       " 63: 'j',\n",
       " 64: 'k',\n",
       " 65: 'l',\n",
       " 66: 'm',\n",
       " 67: 'n',\n",
       " 68: 'o',\n",
       " 69: 'p',\n",
       " 70: 'q',\n",
       " 71: 'r',\n",
       " 72: 's',\n",
       " 73: 't',\n",
       " 74: 'u',\n",
       " 75: 'v',\n",
       " 76: 'w',\n",
       " 77: 'x',\n",
       " 78: 'y',\n",
       " 79: 'z'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ff6590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, data, partition):\n",
    "        self.data = data\n",
    "        self.partition = partition\n",
    "        self.num_captions = 5\n",
    "        self.max_len = TEXT_MAX_LEN\n",
    "        self.img_proc = torch.nn.Sequential(\n",
    "            v2.ToImage(),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Resize((224, 224), antialias=True),\n",
    "            v2.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.partition)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.num_captions*self.partition[idx]\n",
    "        item = self.data.iloc[real_idx: real_idx+self.num_captions]\n",
    "        ## image processing\n",
    "        img_name = item.image.reset_index(drop=True)[0]\n",
    "        img = Image.open(f'{img_path}{img_name}').convert('RGB')\n",
    "        img = self.img_proc(img)\n",
    "    \n",
    "        ## caption processing\n",
    "        caption = item.caption.reset_index(drop=True)[random.choice(list(range(self.num_captions)))]\n",
    "        cap_list = list(caption)\n",
    "        final_list = [chars[0]]\n",
    "        final_list.extend(cap_list)\n",
    "        final_list.extend([chars[1]])\n",
    "        gap = self.max_len - len(final_list)\n",
    "        final_list.extend([chars[2]]*gap)\n",
    "        cap_idx = torch.Tensor([char2idx[i] for i in final_list])\n",
    "        return img, cap_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b652abd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = ResNetModel.from_pretrained('microsoft/resnet-18').to(DEVICE)\n",
    "        self.gru = nn.GRU(512, 512, num_layers=1)\n",
    "        self.proj = nn.Linear(512, NUM_CHAR)\n",
    "        self.embed = nn.Embedding(NUM_CHAR, 512)\n",
    "\n",
    "    def forward(self, img):\n",
    "        batch_size = img.shape[0]\n",
    "        feat = self.resnet(img)\n",
    "        feat = feat.pooler_output.squeeze(-1).squeeze(-1).unsqueeze(0) # 1, batch, 512\n",
    "        start = torch.tensor(char2idx['<SOS>']).to(DEVICE)\n",
    "        start_embed = self.embed(start) # 512\n",
    "        start_embeds = start_embed.repeat(batch_size, 1).unsqueeze(0) # 1, batch, 512\n",
    "        inp = start_embeds\n",
    "        hidden = feat\n",
    "        for t in range(TEXT_MAX_LEN-1): # rm <SOS>\n",
    "            out, hidden = self.gru(inp, hidden)\n",
    "            inp = torch.cat((inp, out[-1:]), dim=0) # N, batch, 512\n",
    "    \n",
    "        res = inp.permute(1, 0, 2) # batch, seq, 512\n",
    "        res = self.proj(res) # batch, seq, 80\n",
    "        res = res.permute(0, 2, 1) # batch, 80, seq\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82acf476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_17676\\1240665556.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  caption1 = torch.tensor(caption1)\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_17676\\1240665556.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  caption2 = torch.tensor(caption2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3829, grad_fn=<NllLoss2DBackward0>)\n"
     ]
    }
   ],
   "source": [
    "'''A simple example to calculate loss of a single batch (size 2)'''\n",
    "dataset = Data(data, partitions['train'])\n",
    "img1, caption1 = next(iter(dataset))\n",
    "img2, caption2 = next(iter(dataset))\n",
    "caption1 = torch.tensor(caption1)\n",
    "caption2 = torch.tensor(caption2)\n",
    "img = torch.cat((img1.unsqueeze(0), img2.unsqueeze(0)))\n",
    "caption = torch.cat((caption1.unsqueeze(0), caption2.unsqueeze(0)))\n",
    "img, caption = img.to(DEVICE), caption.to(DEVICE)\n",
    "model = Model().to(DEVICE)\n",
    "pred = model(img)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "caption = caption.long()\n",
    "loss = crit(pred, caption)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3606f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Alex\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Alex\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Alex\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'bleu': 0.5946035575013605,\n",
       "  'precisions': [0.875, 0.7142857142857143, 0.5, 0.4],\n",
       "  'brevity_penalty': 1.0,\n",
       "  'length_ratio': 1.0,\n",
       "  'translation_length': 8,\n",
       "  'reference_length': 8},\n",
       " {'rouge1': 0.8571428571428571,\n",
       "  'rouge2': 0.6666666666666666,\n",
       "  'rougeL': 0.8571428571428571,\n",
       "  'rougeLsum': 0.8571428571428571},\n",
       " {'meteor': 0.864795918367347})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''metrics'''\n",
    "bleu = evaluate.load('bleu')\n",
    "meteor = evaluate.load('meteor')\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "reference = [['A child in a pink dress is climbing up a set of stairs in an entry way .', 'A girl going into a wooden building .']]\n",
    "prediction = ['A girl goes into a wooden building .']\n",
    "\n",
    "res_b = bleu.compute(predictions=prediction, references=reference)\n",
    "res_r = rouge.compute(predictions=prediction, references=reference)\n",
    "res_m = meteor.compute(predictions=prediction, references=reference)\n",
    "\n",
    "res_b, res_r, res_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7595f1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'bleu': 0.4723665527410147,\n",
       "  'precisions': [1.0, 1.0, 1.0, 1.0],\n",
       "  'brevity_penalty': 0.4723665527410147,\n",
       "  'length_ratio': 0.5714285714285714,\n",
       "  'translation_length': 4,\n",
       "  'reference_length': 7},\n",
       " {'rouge1': 0.7272727272727273,\n",
       "  'rouge2': 0.6666666666666666,\n",
       "  'rougeL': 0.7272727272727273,\n",
       "  'rougeLsum': 0.7272727272727273},\n",
       " {'meteor': 0.5923507462686567})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = [['A child is running in the campus']]\n",
    "pred1 = ['A child is running']\n",
    "\n",
    "res_b = bleu.compute(predictions=pred1, references=ref)\n",
    "res_r = rouge.compute(predictions=pred1, references=ref)\n",
    "res_m = meteor.compute(predictions=pred1, references=ref)\n",
    "\n",
    "res_b, res_r, res_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe24da77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'bleu': 0.0,\n",
       "  'precisions': [1.0, 1.0, 1.0, 0.0],\n",
       "  'brevity_penalty': 0.2635971381157267,\n",
       "  'length_ratio': 0.42857142857142855,\n",
       "  'translation_length': 3,\n",
       "  'reference_length': 7},\n",
       " {'rouge1': 0.6, 'rouge2': 0.5, 'rougeL': 0.6, 'rougeLsum': 0.6},\n",
       " {'meteor': 0.44612794612794615})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = [['A child is running in the campus']]\n",
    "pred1 = ['A child is']\n",
    "\n",
    "res_b = bleu.compute(predictions=pred1, references=ref)\n",
    "res_r = rouge.compute(predictions=pred1, references=ref)\n",
    "res_m = meteor.compute(predictions=pred1, references=ref)\n",
    "\n",
    "res_b, res_r, res_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca1afd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'bleu': 0.0,\n",
       "  'precisions': [1.0, 0.5, 0.0, 0.0],\n",
       "  'brevity_penalty': 0.2635971381157267,\n",
       "  'length_ratio': 0.42857142857142855,\n",
       "  'translation_length': 3,\n",
       "  'reference_length': 7},\n",
       " {'rouge1': 0.6, 'rouge2': 0.25, 'rougeL': 0.6, 'rougeLsum': 0.6},\n",
       " {'meteor': 0.3872053872053872},\n",
       " {'meteor': 0.45454545454545453})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = [['A child is running in the campus']]\n",
    "pred1 = ['A child campus']\n",
    "\n",
    "res_b = bleu.compute(predictions=pred1, references=ref)\n",
    "res_r = rouge.compute(predictions=pred1, references=ref)\n",
    "res_m = meteor.compute(predictions=pred1, references=ref)\n",
    "res_m_sin = meteor.compute(predictions=pred1, references=ref, gamma=0) # no penalty by setting gamma to 0\n",
    "\n",
    "res_b, res_r, res_m, res_m_sin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980bac05",
   "metadata": {},
   "source": [
    "Final metric we use for challenge 3: BLEU1, BLEU2, ROUGE-L, METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5433823c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BLEU-1:26.4%, BLEU2:18.6%, ROUGE-L:60.0%, METEOR:38.7%'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = [['A child is running in the campus']]\n",
    "pred1 = ['A child campus']\n",
    "\n",
    "bleu1 = bleu.compute(predictions=pred1, references=ref, max_order=1)\n",
    "bleu2 = bleu.compute(predictions=pred1, references=ref, max_order=2)\n",
    "res_r = rouge.compute(predictions=pred1, references=ref)\n",
    "res_m = meteor.compute(predictions=pred1, references=ref)\n",
    "\n",
    "f\"BLEU-1:{bleu1['bleu']*100:.1f}%, BLEU2:{bleu2['bleu']*100:.1f}%, ROUGE-L:{res_r['rougeL']*100:.1f}%, METEOR:{res_m['meteor']*100:.1f}%\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf5d9d",
   "metadata": {},
   "source": [
    "Now it is your turn! Try to finish the code below to run the train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = Data(data, partitions['train'])\n",
    "dataloader_train = DataLoader(data_train, batch_size=4, shuffle=True)\n",
    "batch= next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9835fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(EPOCHS):\n",
    "    data_train = Data(data, partitions['train'])\n",
    "    data_valid = Data(data, partitions['valid'])\n",
    "    data_test = Data(data, partitions['test'])\n",
    "\n",
    "    dataloader_train = DataLoader(data_train, batch_size=4, shuffle=True)\n",
    "    dataloader_valid = DataLoader(data_valid, batch_size=4, shuffle=True)\n",
    "    dataloader_test = DataLoader(data_test, batch_size=4, shuffle=True)\n",
    "    \n",
    "    model = Model().to(DEVICE)\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    metric = \"bleu\"\n",
    "    #metric = \"bleu2\"\n",
    "    #metric = \"rouge\"\n",
    "    #metric = \"meteor\"\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(\"Entrando en la función\")\n",
    "        loss, res = train_one_epoch(model, optimizer, crit, metric, dataloader_train)\n",
    "        print(f'train loss: {loss:.2f}, metric: {res:.2f}, epoch: {epoch}')\n",
    "        loss_v, res_v = eval_epoch(model, crit, metric, dataloader_valid)\n",
    "        print(f'valid loss: {loss_v:.2f}, metric: {res_v:.2f}')\n",
    "    loss_t, res_t = eval_epoch(model, crit, metric, dataloader_test)\n",
    "    print(f'test loss: {loss_t:.2f}, metric: {res_t:.2f}')\n",
    "    \n",
    "def train_one_epoch(model, optimizer, crit, metric, dataloader):\n",
    "    total_loss= 0.0\n",
    "    total_metric= 0.0\n",
    "    print(\"Entrando al batch\")\n",
    "    for batch in dataloader:\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.to(DEVICE) \n",
    "        \n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        print(\"Targets y inputs pasados al device\")\n",
    "        \n",
    "        outputs= model(inputs)\n",
    "        targets = targets.long()\n",
    "\n",
    "        print(\"Targets pasados a long\")\n",
    "        print(\"Calculando loss\")\n",
    "        loss= crit(outputs,targets)\n",
    "        print(\"Loss calculada\")\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        print(outputs.shape)\n",
    "        print(outputs)\n",
    "        print(targets)\n",
    "        print(targets.shape)\n",
    "        \n",
    "\n",
    "        # Take argmax to get most probable character indices\n",
    "        outputs_idx = torch.argmax(outputs, dim=-1) # el dim -1 es para decir que quieres encontrar el indice del valor máximo del tensor de probabilidades\n",
    "\n",
    "        # Convert outputs and targets to sentences\n",
    "        targets_sentence = [\"\".join(idx2char[idx.item()] for idx in target if idx.item() not in [char2idx['<EOS>'], char2idx['<PAD>'], char2idx['<SOS>']]) for target in targets]\n",
    "        print(targets_sentence)\n",
    "        outputs_sentence = [\"\".join(idx2char[idx.item()] for idx in output if idx.item() not in [char2idx['<EOS>'], char2idx['<PAD>'], char2idx['<SOS>']]) for output in outputs_idx]\n",
    "        print(outputs_sentence)\n",
    "        \n",
    "        #outputs_sentence = ''.join([idx2char[idx.item()] for idx in outputs if idx.item() not in [char2idx['<EOS>'], char2idx['<PAD>'], char2idx['<SOS>']]])\n",
    "        #targets_sentence = ''.join([idx2char[idx.item()] for idx in targets if idx.item() not in [char2idx['<EOS>'], char2idx['<PAD>'], char2idx['<SOS>']]])\n",
    "\n",
    "        print(\"Outputs y targets sentence calculados\")\n",
    "        print(\"Output sentence:\",outputs_sentence, \"Target sentence:\",targets_sentence)\n",
    "        \n",
    "        \n",
    "        METRIC = evaluate.load(str(metric).lower())\n",
    "\n",
    "        print(\"Metrica cargada\")\n",
    "\n",
    "        if metric == \"bleu\":\n",
    "                metriccompute = METRIC.compute(predictions=outputs_sentence, references=targets_sentence,max_order=1 )\n",
    "        elif metric == \"bleu2\":\n",
    "                metriccompute = METRIC.compute(predictions=outputs_sentence, references=targets_sentence,max_order=2 )\n",
    "        else:\n",
    "                metriccompute = METRIC.compute(predictions=outputs, references=targets )\n",
    "\n",
    "        print(\"Metrica calculada\")\n",
    "\n",
    "        if metric == \"rouge\":\n",
    "                total_metric += metriccompute['rougeL']\n",
    "        else:\n",
    "                total_metric += metriccompute[str(metric).lower()]\n",
    "        \n",
    "        print(\"Metrica añadida\")\n",
    "        \n",
    "        \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_metric = total_metric / len(dataloader)\n",
    "    print(f'train loss: {avg_loss:.2f}, metric: {avg_metric:.2f}')\n",
    "    print(f'train loss: {avg_loss:.2f}')\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "def eval_epoch(model, crit, metric, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(DEVICE) \n",
    "            targets = targets.to(DEVICE)\n",
    "\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            targets = targets.long()\n",
    "            loss = crit(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "\n",
    "        \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    print(f'valid loss: {avg_loss:.2f}')\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of your model is a 3D tensor because it's providing a probability distribution over your vocabulary for each position in each sequence in the batch. This is a common output for models dealing with sequence data like text or time series.\n",
    "\n",
    "Your reference data (`targets`) is a 2D tensor because it contains the actual character indices (not probabilities) for each position in each sequence.\n",
    "\n",
    "The line `outputs_idx = torch.argmax(outputs, dim=-1)` is converting the probability distributions in `outputs` to character indices. The `torch.argmax` function returns the index of the maximum value in a tensor along a specified dimension. When `dim=-1`, it's looking at the last dimension of `outputs` (the feature dimension, which represents the vocabulary in your case). \n",
    "\n",
    "So for each position in each sequence, it's picking the character with the highest probability according to the model. The result is a 2D tensor of the same shape as `targets`, which allows you to compare the model's predictions with the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrando en la función\n",
      "Entrando al batch\n",
      "Targets y inputs pasados al device\n",
      "Targets pasados a long\n",
      "Calculando loss\n",
      "Loss calculada\n",
      "torch.Size([4, 80, 201])\n",
      "tensor([[[ 0.0356, -0.6234, -0.3672,  ...,  0.0372,  0.0372,  0.0372],\n",
      "         [-0.5949, -0.8397, -0.4734,  ..., -0.0420, -0.0420, -0.0420],\n",
      "         [ 0.1728, -0.0685, -0.1010,  ..., -0.0361, -0.0361, -0.0361],\n",
      "         ...,\n",
      "         [-0.1318, -0.6592, -0.0888,  ..., -0.0460, -0.0460, -0.0460],\n",
      "         [-0.7433,  0.3839,  0.2003,  ...,  0.0791,  0.0791,  0.0791],\n",
      "         [-0.2278,  0.4554,  0.2508,  ..., -0.0339, -0.0339, -0.0339]],\n",
      "\n",
      "        [[ 0.0356, -0.7423, -0.1645,  ...,  0.0372,  0.0372,  0.0372],\n",
      "         [-0.5949, -0.0999, -0.2304,  ..., -0.0420, -0.0420, -0.0420],\n",
      "         [ 0.1728,  0.2863, -0.0329,  ..., -0.0361, -0.0361, -0.0361],\n",
      "         ...,\n",
      "         [-0.1318, -0.1701,  0.1424,  ..., -0.0460, -0.0460, -0.0460],\n",
      "         [-0.7433, -0.0603, -0.0614,  ...,  0.0791,  0.0791,  0.0791],\n",
      "         [-0.2278,  0.1759,  0.1740,  ..., -0.0339, -0.0339, -0.0339]],\n",
      "\n",
      "        [[ 0.0356, -0.6814, -0.1505,  ...,  0.0372,  0.0372,  0.0372],\n",
      "         [-0.5949, -0.3832, -0.2805,  ..., -0.0420, -0.0420, -0.0420],\n",
      "         [ 0.1728,  0.7229,  0.1285,  ..., -0.0361, -0.0361, -0.0361],\n",
      "         ...,\n",
      "         [-0.1318, -0.2309, -0.0537,  ..., -0.0460, -0.0460, -0.0460],\n",
      "         [-0.7433,  0.2136,  0.0961,  ...,  0.0791,  0.0791,  0.0791],\n",
      "         [-0.2278,  0.0221,  0.1806,  ..., -0.0339, -0.0339, -0.0339]],\n",
      "\n",
      "        [[ 0.0356, -0.4781, -0.2628,  ...,  0.0372,  0.0372,  0.0372],\n",
      "         [-0.5949, -0.6540, -0.2982,  ..., -0.0420, -0.0420, -0.0420],\n",
      "         [ 0.1728, -0.0688, -0.2047,  ..., -0.0361, -0.0361, -0.0361],\n",
      "         ...,\n",
      "         [-0.1318, -0.2226,  0.1373,  ..., -0.0460, -0.0460, -0.0460],\n",
      "         [-0.7433,  0.2232,  0.1110,  ...,  0.0791,  0.0791,  0.0791],\n",
      "         [-0.2278,  0.1705,  0.1447,  ..., -0.0339, -0.0339, -0.0339]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([[ 0, 28,  3, 65, 62, 73, 73, 65, 58,  3, 55, 68, 78,  3, 62, 67,  3, 54,\n",
      "          3, 73, 58, 54, 65,  3, 74, 67, 62, 59, 68, 71, 66,  3, 72, 76, 62, 67,\n",
      "         60, 62, 67, 60,  3, 54,  3, 55, 54, 72, 58, 55, 54, 65, 65,  3, 55, 54,\n",
      "         73,  3, 13,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2],\n",
      "        [ 0, 28,  3, 72, 66, 54, 65, 65,  3, 60, 62, 71, 65,  3, 57, 71, 58, 72,\n",
      "         72, 58, 57,  3, 62, 67,  3, 54,  3, 71, 58, 57,  3, 72, 76, 58, 54, 73,\n",
      "         58, 71,  3, 69, 65, 54, 78, 62, 67, 60,  3, 61, 74, 65, 54,  3, 61, 68,\n",
      "         68, 69,  3, 68, 67,  3, 54,  3, 72, 62, 57, 58, 76, 54, 65, 64,  3, 62,\n",
      "         67,  3, 54,  3, 67, 58, 62, 60, 61, 55, 68, 71, 61, 68, 68, 57,  3, 13,\n",
      "          1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2],\n",
      "        [ 0, 28,  3, 72, 61, 54, 76, 65, 58, 57,  3, 76, 68, 66, 54, 67,  3, 72,\n",
      "         62, 73, 72,  3, 76, 62, 73, 61,  3, 68, 73, 61, 58, 71, 72,  3, 13,  1,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2],\n",
      "        [ 0, 28,  3, 66, 54, 67,  3, 72, 73, 54, 67, 57, 72,  3, 54, 73, 68, 69,\n",
      "          3, 54,  3, 71, 68, 56, 64, 78,  3, 56, 65, 62, 59, 59,  3, 68, 75, 58,\n",
      "         71,  3, 73, 61, 58,  3, 76, 54, 73, 58, 71,  3, 13,  1,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2]])\n",
      "torch.Size([4, 201])\n",
      "['A little boy in a teal uniform swinging a baseball bat .', 'A small girl dressed in a red sweater playing hula hoop on a sidewalk in a neighborhood .', 'A shawled woman sits with others .', 'A man stands atop a rocky cliff over the water .']\n",
      "['8&!\"!62! \\'!#0 &s ', 'A#!  & 34!   (8.0O,7', 'D#!=! &,!-\" &! )V7', '2&\"6 ! ,!;  4']\n",
      "Outputs y targets sentence calculados\n",
      "Output sentence: ['8&!\"!62! \\'!#0 &s ', 'A#!  & 34!   (8.0O,7', 'D#!=! &,!-\" &! )V7', '2&\"6 ! ,!;  4'] Target sentence: ['A little boy in a teal uniform swinging a baseball bat .', 'A small girl dressed in a red sweater playing hula hoop on a sidewalk in a neighborhood .', 'A shawled woman sits with others .', 'A man stands atop a rocky cliff over the water .']\n",
      "Metrica cargada\n",
      "Metrica calculada\n",
      "Metrica añadida\n",
      "Targets y inputs pasados al device\n",
      "Targets pasados a long\n",
      "Calculando loss\n",
      "Loss calculada\n",
      "torch.Size([4, 80, 201])\n",
      "tensor([[[ 3.5584e-02, -5.6647e-01, -2.2058e-01,  ...,  3.7164e-02,\n",
      "           3.7164e-02,  3.7164e-02],\n",
      "         [-5.9491e-01, -4.4505e-01, -2.7799e-01,  ..., -4.1983e-02,\n",
      "          -4.1983e-02, -4.1983e-02],\n",
      "         [ 1.7278e-01,  3.3633e-01,  5.4704e-02,  ..., -3.6056e-02,\n",
      "          -3.6056e-02, -3.6056e-02],\n",
      "         ...,\n",
      "         [-1.3184e-01, -2.7532e-01,  6.3947e-02,  ..., -4.5978e-02,\n",
      "          -4.5978e-02, -4.5978e-02],\n",
      "         [-7.4327e-01,  1.0961e-01,  5.5748e-02,  ...,  7.9065e-02,\n",
      "           7.9065e-02,  7.9065e-02],\n",
      "         [-2.2781e-01,  3.9077e-01,  2.6975e-01,  ..., -3.3902e-02,\n",
      "          -3.3902e-02, -3.3902e-02]],\n",
      "\n",
      "        [[ 3.5584e-02, -4.1628e-01, -1.4806e-01,  ...,  3.7164e-02,\n",
      "           3.7164e-02,  3.7164e-02],\n",
      "         [-5.9491e-01, -7.0071e-01, -4.3054e-01,  ..., -4.1983e-02,\n",
      "          -4.1983e-02, -4.1983e-02],\n",
      "         [ 1.7278e-01,  2.9467e-01, -4.0096e-02,  ..., -3.6056e-02,\n",
      "          -3.6056e-02, -3.6056e-02],\n",
      "         ...,\n",
      "         [-1.3184e-01, -3.2461e-01, -5.9655e-03,  ..., -4.5978e-02,\n",
      "          -4.5978e-02, -4.5978e-02],\n",
      "         [-7.4327e-01,  1.6023e-01,  1.2591e-04,  ...,  7.9065e-02,\n",
      "           7.9065e-02,  7.9065e-02],\n",
      "         [-2.2781e-01,  1.7174e-01,  1.8311e-01,  ..., -3.3902e-02,\n",
      "          -3.3902e-02, -3.3902e-02]],\n",
      "\n",
      "        [[ 3.5584e-02, -7.0055e-01, -1.9448e-01,  ...,  3.7164e-02,\n",
      "           3.7164e-02,  3.7164e-02],\n",
      "         [-5.9491e-01, -2.7965e-01, -1.9049e-01,  ..., -4.1983e-02,\n",
      "          -4.1983e-02, -4.1983e-02],\n",
      "         [ 1.7278e-01,  1.7188e-01, -1.3623e-01,  ..., -3.6056e-02,\n",
      "          -3.6056e-02, -3.6056e-02],\n",
      "         ...,\n",
      "         [-1.3184e-01, -2.2292e-01,  1.2810e-01,  ..., -4.5978e-02,\n",
      "          -4.5978e-02, -4.5978e-02],\n",
      "         [-7.4327e-01,  3.1341e-01,  1.5401e-01,  ...,  7.9065e-02,\n",
      "           7.9065e-02,  7.9065e-02],\n",
      "         [-2.2781e-01, -1.3038e-01,  3.7741e-03,  ..., -3.3902e-02,\n",
      "          -3.3902e-02, -3.3902e-02]],\n",
      "\n",
      "        [[ 3.5584e-02, -9.0252e-01, -3.4696e-01,  ...,  3.7164e-02,\n",
      "           3.7164e-02,  3.7164e-02],\n",
      "         [-5.9491e-01, -6.1332e-01, -3.4606e-01,  ..., -4.1983e-02,\n",
      "          -4.1983e-02, -4.1983e-02],\n",
      "         [ 1.7278e-01,  7.7299e-02, -1.0340e-01,  ..., -3.6056e-02,\n",
      "          -3.6056e-02, -3.6056e-02],\n",
      "         ...,\n",
      "         [-1.3184e-01, -4.7847e-01, -6.6392e-02,  ..., -4.5978e-02,\n",
      "          -4.5978e-02, -4.5978e-02],\n",
      "         [-7.4327e-01,  8.8188e-02,  9.5503e-02,  ...,  7.9065e-02,\n",
      "           7.9065e-02,  7.9065e-02],\n",
      "         [-2.2781e-01,  3.7531e-01,  2.6243e-01,  ..., -3.3902e-02,\n",
      "          -3.3902e-02, -3.3902e-02]]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[ 0, 47, 76, 68,  3, 76, 68, 66, 54, 67,  3, 54, 71, 58,  3, 57, 68, 62,\n",
      "         67, 60,  3, 64, 54, 71, 54, 73, 58,  3, 13,  1,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2],\n",
      "        [ 0, 28,  3, 55, 71, 68, 76, 67,  3, 57, 68, 60,  3, 71, 58, 54, 56, 61,\n",
      "         58, 72,  3, 59, 68, 71,  3, 54,  3, 73, 58, 67, 67, 62, 72,  3, 55, 54,\n",
      "         65, 65,  3, 13,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2],\n",
      "        [ 0, 28,  3, 66, 54, 67,  3, 62, 67,  3, 72, 61, 68, 71, 73, 72,  3, 68,\n",
      "         67,  3, 54,  3, 55, 65, 54, 56, 64,  3, 55, 62, 56, 78, 56, 65, 58,  3,\n",
      "         13,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2],\n",
      "        [ 0, 47, 76, 68,  3, 65, 62, 67, 58, 72,  3, 68, 59,  3, 56, 68, 65, 68,\n",
      "         71, 59, 74, 65,  3, 56, 54, 71, 72,  3, 71, 54, 56, 62, 67, 60,  3, 68,\n",
      "         67,  3, 54,  3, 71, 54, 56, 58, 73, 71, 54, 56, 64,  3, 13,  1,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2]])\n",
      "torch.Size([4, 201])\n",
      "['Two woman are doing karate .', 'A brown dog reaches for a tennis ball .', 'A man in shorts on a black bicycle .', 'Two lines of colorful cars racing on a racetrack .']\n",
      "['?&!9   .    =&! u ', '2&! ( N!\" 5#&Q ', '6\"!,N&65!  H\"9!L) ', '?#\"7   2-!   !.\" 12s- ']\n",
      "Outputs y targets sentence calculados\n",
      "Output sentence: ['?&!9   .    =&! u ', '2&! ( N!\" 5#&Q ', '6\"!,N&65!  H\"9!L) ', '?#\"7   2-!   !.\" 12s- '] Target sentence: ['Two woman are doing karate .', 'A brown dog reaches for a tennis ball .', 'A man in shorts on a black bicycle .', 'Two lines of colorful cars racing on a racetrack .']\n",
      "Metrica cargada\n",
      "Metrica calculada\n",
      "Metrica añadida\n",
      "Targets y inputs pasados al device\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alex\\Desktop\\Universidad\\Third Course\\First Semester\\Vision & Learning\\PROJECT 3\\vl3\\vision_learning_project3\\Baseline Model and Metrics.ipynb Cell 21\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train(\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\Alex\\Desktop\\Universidad\\Third Course\\First Semester\\Vision & Learning\\PROJECT 3\\vl3\\vision_learning_project3\\Baseline Model and Metrics.ipynb Cell 21\u001b[0m line \u001b[0;36mtrain\u001b[1;34m(EPOCHS)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X26sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEntrando en la función\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     loss, res \u001b[39m=\u001b[39m train_one_epoch(model, optimizer, crit, metric, dataloader_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, metric: \u001b[39m\u001b[39m{\u001b[39;00mres\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, epoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     loss_v, res_v \u001b[39m=\u001b[39m eval_epoch(model, crit, metric, dataloader_valid)\n",
      "\u001b[1;32mc:\\Users\\Alex\\Desktop\\Universidad\\Third Course\\First Semester\\Vision & Learning\\PROJECT 3\\vl3\\vision_learning_project3\\Baseline Model and Metrics.ipynb Cell 21\u001b[0m line \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, optimizer, crit, metric, dataloader)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X26sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X26sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTargets y inputs pasados al device\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X26sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m outputs\u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X26sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mlong()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X26sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTargets pasados a long\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\Alex\\Desktop\\Universidad\\Third Course\\First Semester\\Vision & Learning\\PROJECT 3\\vl3\\vision_learning_project3\\Baseline Model and Metrics.ipynb Cell 21\u001b[0m line \u001b[0;36mModel.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m hidden \u001b[39m=\u001b[39m feat\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(TEXT_MAX_LEN\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m): \u001b[39m# rm <SOS>\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X26sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     out, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgru(inp, hidden)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     inp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((inp, out[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:]), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m# N, batch, 512\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m res \u001b[39m=\u001b[39m inp\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m) \u001b[39m# batch, seq, 512\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1102\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m   1101\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1102\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mgru(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m   1103\u001b[0m                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m   1104\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m   1106\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alex\\Desktop\\Universidad\\Third Course\\First Semester\\Vision & Learning\\PROJECT 3\\vl3\\vision_learning_project3\\Baseline Model and Metrics.ipynb Cell 20\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Alex/Desktop/Universidad/Third%20Course/First%20Semester/Vision%20%26%20Learning/PROJECT%203/vl3/vision_learning_project3/Baseline%20Model%20and%20Metrics.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m outputs\n",
      "\u001b[1;31mNameError\u001b[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch= next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "onecaption=batch[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "onecaption_chr = ''.join([idx2char[idx.item()] for idx in onecaption if idx.item() not in [char2idx['<EOS>'], char2idx['<PAD>'], char2idx['<SOS>']]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A painting of a man riding a mountain bike on a mountain trail .'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
